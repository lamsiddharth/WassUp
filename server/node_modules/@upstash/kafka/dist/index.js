"use strict";var l=Object.defineProperty;var y=Object.getOwnPropertyDescriptor;var P=Object.getOwnPropertyNames;var b=Object.prototype.hasOwnProperty;var g=(o,t)=>{for(var e in t)l(o,e,{get:t[e],enumerable:!0})},R=(o,t,e,s)=>{if(t&&typeof t=="object"||typeof t=="function")for(let i of P(t))!b.call(o,i)&&i!==e&&l(o,i,{get:()=>t[i],enumerable:!(s=y(t,i))||s.enumerable});return o};var T=o=>R(l({},"__esModule",{value:!0}),o);var C={};g(C,{Kafka:()=>f,UpstashError:()=>p});module.exports=T(C);var a=class{client;constructor(t){this.client=t}async topics(){return await this.client.get({path:["topics"]})}async consumers(){return await this.client.get({path:["consumers"]})}async removeConsumerInstance(t,e){await this.client.post({path:["delete-consumer",t,e]})}async committedOffsets(t){return await this.client.post({path:["committed",t.consumerGroupId,t.instanceId],body:t.topicPartition?[t.topicPartition]:t.topicPartitions})}async topicPartitionOffsets(t){return await this.client.post({path:["offsets",t.timestamp.toString()],body:t.topicPartition?[t.topicPartition]:t.topicPartitions})}};function h(o){let t="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",e=o.length-1,s=-1,i="";for(;s<e;){let n=o.charCodeAt(++s)<<16|o.charCodeAt(++s)<<8|o.charCodeAt(++s);i+=t[n>>>18&63]+t[n>>>12&63]+t[n>>>6&63]+t[n&63]}let r=o.length%3;if(r>0)for(i=i.slice(0,r-3);i.length%4!==0;)i+="=";return i}var c=class{client;constructor(t){this.client=t}async fetch(t,e={parallel:!0}){let s=[t];return e?.parallel&&(s=(t.topicPartitionOffsets??[]).map(r=>({...r,timeout:t.timeout})),t.topic&&s.push({topic:t.topic,partition:t.partition,offset:t.offset,timeout:t.timeout})),(await Promise.all(s.map(async r=>await this.client.post({path:["fetch"],body:r})))).flat()}async consume(t){let e={};t.topics.length===1?e.topic=t.topics[0]:e.topics=t.topics,typeof t.timeout=="number"&&(e.timeout=t.timeout);let s={};return typeof t.autoCommit=="boolean"&&(s["Kafka-Enable-Auto-Commit"]=t.autoCommit.toString()),typeof t.autoCommitInterval=="number"&&(s["Kafka-Auto-Commit-Interval"]=t.autoCommitInterval.toString()),typeof t.autoOffsetReset=="string"&&(s["Kafka-Auto-Offset-Reset"]=t.autoOffsetReset),await this.client.post({path:["consume",t.consumerGroupId,t.instanceId],headers:s,body:e})}async commit(t){return await this.client.post({path:["commit",t.consumerGroupId,t.instanceId],body:t.offset})}async committed(t){return await this.client.post({path:["committed",t.consumerGroupId,t.instanceId],body:t.topicPartitions})}};var p=class extends Error{result;error;status;constructor(t){super(t.error),this.name="UpstashError",this.result=t.result,this.error=t.error,this.status=t.status}};var u=class{baseUrl;headers;constructor(t){this.baseUrl=t.baseUrl.replace(/\/$/,""),this.headers=t.headers??{}}async request(t,e){let s={"Content-Type":"application/json",...this.headers,...e.headers},i=new Error;for(let r=0;r<=(e.retries??5);r++){r>0&&await new Promise(n=>setTimeout(n,2**r*250));try{let n=await fetch([this.baseUrl,...e.path].join("/"),{method:t,headers:s,keepalive:!0,body:JSON.stringify(e.body)}),d=await n.json();if(!n.ok)throw new p(d);return d}catch(n){i=n}}throw i}async get(t){return await this.request("GET",t)}async post(t){return await this.request("POST",t)}};var m=class{client;constructor(t){this.client=t}async produce(t,e,s){let i={topic:t,value:typeof e=="string"?e:JSON.stringify(e),...s};return(await this.client.post({path:["produce"],body:i}))[0]}async produceMany(t){let e=t.map(({value:s,...i})=>({...i,value:typeof s=="string"?s:JSON.stringify(s)}));return await this.client.post({path:["produce"],body:e})}};var f=class{client;constructor(t){this.client=new u({baseUrl:t.url,headers:{authorization:`Basic ${h(`${t.username}:${t.password}`)}`}})}producer(){return new m(this.client)}consumer(){return new c(this.client)}admin(){return new a(this.client)}};0&&(module.exports={Kafka,UpstashError});
